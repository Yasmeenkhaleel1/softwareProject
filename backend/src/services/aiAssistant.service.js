import OpenAI from "openai";
import Booking from "../models/booking.model.js";
import Service from "../models/expert/service.model.js";
import ExpertProfile from "../models/expert/expertProfile.model.js";

const localAI = new OpenAI({
  baseURL: "http://127.0.0.1:11434/v1",
  apiKey: "ollama",
});

/**
 * ðŸ›  1. Ø¯Ø§Ù„Ø© ØªØ¬Ù…ÙŠØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ù…ÙˆØ¬ÙˆØ¯Ø© ÙˆÙ…Ø¹Ø±ÙØ©)
 */
async function buildCustomerContext(userId) {
  try {
    const [latestBooking, activeCount, totalCount] = await Promise.all([
      Booking.findOne({ customer: userId })
        .sort({ startAt: -1 })
        .populate({ path: "service", select: "title", model: Service })
        .populate({ path: "expert", select: "name", model: ExpertProfile })
        .lean(),
      Booking.countDocuments({
        customer: userId,
        status: { $in: ["PENDING", "CONFIRMED", "IN_PROGRESS"] },
      }),
      Booking.countDocuments({ customer: userId }),
    ]);

    let latestSummary = "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø­Ø¬ÙˆØ²Ø§Øª Ø³Ø§Ø¨Ù‚Ø©.";
    if (latestBooking) {
      latestSummary = 
        `- Ø§Ù„Ø®Ø¯Ù…Ø©: ${latestBooking.service?.title || "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"}\n` +
        `- Ø§Ù„Ø®Ø¨ÙŠØ±: ${latestBooking.expert?.name || "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"}\n` +
        `- Ø§Ù„Ø­Ø§Ù„Ø©: ${latestBooking.status}\n` +
        `- Ø§Ù„ØªØ§Ø±ÙŠØ®: ${latestBooking.startAt?.toLocaleDateString('ar-EG') || ""}`;
    }

    return {
      activeBookingsCount: activeCount,
      totalBookingsCount: totalCount,
      latestBookingSummary: latestSummary,
    };
  } catch (error) {
    console.error("Error building context:", error);
    return { activeBookingsCount: 0, totalBookingsCount: 0, latestBookingSummary: "Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª" };
  }
}

/**
 * ðŸ§  2. Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
 */
async function callLLM({ systemPrompt, userMessage, history }) {
  try {
    const response = await localAI.chat.completions.create({
      model: "llama3.2",
      messages: [
        { role: "system", content: systemPrompt },
        ...history,
        { role: "user", content: userMessage },
      ],
      temperature: 0.7,
    });
    return response.choices[0].message.content.trim();
  } catch (error) {
    console.error("AI Call Error:", error);
    return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ù„Ø§ ÙŠØ³ØªØ¬ÙŠØ¨ Ø­Ø§Ù„ÙŠØ§Ù‹.";
  }
}

/**
 * ðŸŽ¯ 3. Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…ØµØ¯Ø±Ø© (Ø§Ù„ØªÙŠ ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡Ø§ Ù…Ù† Ø§Ù„Ù€ Controller)
 */
export async function generateAssistantReply({ userId, userQuestion, historyMessages }) {
  // âœ… Ø§Ù„Ø¢Ù† Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ø¹Ø±ÙØ© ÙÙŠ Ø§Ù„Ø£Ø¹Ù„Ù‰ ÙˆÙ„Ù† ÙŠØ¸Ù‡Ø± Ø§Ù„Ø®Ø·Ø£
  const ctx = await buildCustomerContext(userId);

  // Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
  if (userQuestion.includes("Ø­Ø¬Ø²") || userQuestion.includes("booking")) {
     // ÙŠÙ…ÙƒÙ†Ùƒ ÙˆØ¶Ø¹ Ù…Ù†Ø·Ù‚ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ù‡Ù†Ø§ Ø£Ùˆ ØªØ±ÙƒÙ‡ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
  }

  const systemPrompt = `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ù…Ù†ØµØ© Lost Treasures. 
    Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: Ù„Ø¯ÙŠÙ‡ ${ctx.activeBookingsCount} Ø­Ø¬ÙˆØ²Ø§Øª Ù†Ø´Ø·Ø©. 
    Ø¢Ø®Ø± Ø­Ø¬Ø² Ù„Ù‡: ${ctx.latestBookingSummary}`;

  const history = (historyMessages || []).map(m => ({
    role: m.role === "bot" ? "assistant" : "user",
    content: m.content
  }));

  const reply = await callLLM({ systemPrompt, userMessage: userQuestion, history });

  return { reply, source: "AI" };
}